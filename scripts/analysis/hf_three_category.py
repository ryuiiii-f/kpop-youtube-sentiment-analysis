import pandas as pd
from transformers import pipeline
from tqdm import tqdm
import warnings
warnings.filterwarnings("ignore")

print("ğŸš€ LOADING HUGGINGFACE MODELS FOR 3-CATEGORY CLASSIFICATION...")

# åŠ è½½é›¶æ ·æœ¬åˆ†ç±»æ¨¡å‹ (å¤šè¯­è¨€æ”¯æŒæ›´å¥½çš„ç‰ˆæœ¬)
classifier = pipeline(
    "zero-shot-classification",
    model="facebook/bart-large-mnli"  # æˆ–è€…è¯•è¯• "microsoft/DialoGPT-medium" 
)

print("âœ… Model loaded successfully!")

# è¯»å–åŸå§‹æ•°æ®
df = pd.read_csv("labeled_comments_hylt_hf.csv")
print(f"ğŸ“Š Total comments to reclassify: {len(df)}")

def classify_fan_type_hf_3category(text):
    """
    ä½¿ç”¨HuggingFaceè¿›è¡Œ3ç±»åˆ†ç±»
    é’ˆå¯¹è‹±éŸ©æ—¥è¯­è¨€ä¼˜åŒ–çš„æ ‡ç­¾è®¾è®¡
    """
    
    if pd.isna(text) or not str(text).strip():
        return "general-praise"
    
    # ä¼˜åŒ–çš„å€™é€‰æ ‡ç­¾ (é’ˆå¯¹å¤šè¯­è¨€ç‰¹ç‚¹)
    candidate_labels = [
        # æ›´å…·ä½“ã€æ›´å®¹æ˜“åŒºåˆ†çš„æ ‡ç­¾æè¿°
        "visual appearance styling fashion looks makeup outfits", # visual-focused
        "music lyrics dance choreography song performance content", # content-focused  
        "general praise love excitement emotional reaction" # general-praise
    ]
    
    try:
        result = classifier(str(text), candidate_labels)
        top_label = result['labels'][0]
        confidence = result['scores'][0]
        
        # æ ‡ç­¾æ˜ å°„
        label_mapping = {
            "visual appearance styling fashion looks makeup outfits": "visual-focused",
            "music lyrics dance choreography song performance content": "content-focused", 
            "general praise love excitement emotional reaction": "general-praise"
        }
        
        # ç½®ä¿¡åº¦é˜ˆå€¼ (3ç±»åº”è¯¥æ›´æœ‰ä¿¡å¿ƒ)
        if confidence < 0.4:  # é™ä½é˜ˆå€¼ï¼Œå› ä¸º3ç±»æ›´å®¹æ˜“åŒºåˆ†
            return "general-praise"  # ä¸ç¡®å®šçš„å½’ä¸ºgeneral-praise
        
        return label_mapping.get(top_label, "general-praise")
        
    except Exception as e:
        print(f"âŒ Classification error: {str(e)}")
        return "general-praise"

# ============================================
# æ‰¹é‡å¤„ç† (ä¼˜åŒ–ç‰ˆæœ¬)
# ============================================

def batch_classify_3category(comments, batch_size=16):
    """æ‰¹é‡åˆ†ç±»ä»¥æé«˜æ•ˆç‡"""
    results = []
    
    print("ğŸ”„ Starting 3-category classification...")
    
    for i in tqdm(range(0, len(comments), batch_size), desc="ğŸ¯ HF 3-category processing"):
        batch = comments[i:i+batch_size]
        
        for comment in batch:
            fan_type = classify_fan_type_hf_3category(comment)
            results.append(fan_type)
    
    return results

# æ‰§è¡Œåˆ†ç±»
comments = df['comment_text'].tolist()
new_fan_types = batch_classify_3category(comments)

# æ›´æ–°æ•°æ®æ¡†
df['fan_type_hf3'] = new_fan_types

# ============================================
# ç»“æœåˆ†æ
# ============================================

print("\nğŸ“Š HUGGINGFACE 3-CATEGORY RESULTS:")
print("="*50)

hf3_counts = df['fan_type_hf3'].value_counts()
for category, count in hf3_counts.items():
    percentage = count/len(df)*100
    print(f"   {category}: {count} ({percentage:.1f}%)")

# è®¡ç®—å…·ä½“åˆ†ç±»æˆåŠŸç‡
specific_categories = hf3_counts.get('visual-focused', 0) + hf3_counts.get('content-focused', 0)
specific_ratio = specific_categories / len(df) * 100
general_ratio = hf3_counts.get('general-praise', 0) / len(df) * 100

print(f"\nğŸ¯ PERFORMANCE METRICS:")
print(f"   âœ… Specific categorization: {specific_ratio:.1f}% (visual + content)")
print(f"   âœ… General praise: {general_ratio:.1f}%")
print(f"   âœ… Compared to original unclear: {100-50:.1f}% vs {specific_ratio:.1f}%")

# ============================================
# è´¨é‡æ£€æŸ¥
# ============================================

print(f"\nğŸ” QUALITY CHECK - SAMPLE CLASSIFICATIONS:")
print("-" * 60)

for category in ['visual-focused', 'content-focused', 'general-praise']:
    if category in hf3_counts.index:
        samples = df[df['fan_type_hf3'] == category].head(3)
        print(f"\nğŸ’ {category.upper()} examples:")
        for idx, row in samples.iterrows():
            comment = str(row['comment_text'])[:70]
            emotion = row['emotion']
            print(f"   '{comment}...'")
            print(f"   â†’ Emotion: {emotion}, Type: {category}")

# ============================================
# è¯­è¨€åˆ†å¸ƒåˆ†æ
# ============================================

def detect_language_pattern(text):
    """ç®€å•çš„è¯­è¨€æ¨¡å¼æ£€æµ‹"""
    text = str(text).lower()
    
    # éŸ©æ–‡å­—ç¬¦
    korean_chars = re.findall(r'[ê°€-í£]', text)
    # æ—¥æ–‡å­—ç¬¦  
    japanese_chars = re.findall(r'[ã²ã‚‰ãŒãªã‚«ã‚¿ã‚«ãƒŠ]|[ä¸€-é¾¯]', text)
    # è‹±æ–‡ä¸ºä¸»
    english_chars = re.findall(r'[a-zA-Z]', text)
    
    total_chars = len(korean_chars) + len(japanese_chars) + len(english_chars)
    
    if total_chars == 0:
        return "mixed"
    
    korean_ratio = len(korean_chars) / total_chars
    japanese_ratio = len(japanese_chars) / total_chars  
    english_ratio = len(english_chars) / total_chars
    
    if korean_ratio > 0.3:
        return "korean-dominant"
    elif japanese_ratio > 0.3:
        return "japanese-dominant"
    elif english_ratio > 0.7:
        return "english-dominant"
    else:
        return "mixed"

# åˆ†æè¯­è¨€åˆ†å¸ƒ
df['language_pattern'] = df['comment_text'].apply(detect_language_pattern)
language_dist = df['language_pattern'].value_counts()

print(f"\nğŸŒ LANGUAGE DISTRIBUTION IN COMMENTS:")
for lang, count in language_dist.items():
    percentage = count/len(df)*100
    print(f"   {lang}: {count} ({percentage:.1f}%)")

# è¯­è¨€ vs åˆ†ç±»æ•ˆæœåˆ†æ
print(f"\nğŸ“Š CLASSIFICATION EFFECTIVENESS BY LANGUAGE:")
for lang in language_dist.index:
    lang_df = df[df['language_pattern'] == lang]
    lang_specific = (lang_df['fan_type_hf3'] != 'general-praise').sum()
    lang_ratio = lang_specific / len(lang_df) * 100 if len(lang_df) > 0 else 0
    print(f"   {lang}: {lang_ratio:.1f}% specific classification")

# ============================================
# ä¿å­˜ç»“æœ
# ============================================

# ä¿å­˜HF 3ç±»ç»“æœ
df_hf3 = df[['comment_text', 'emotion', 'fan_type_hf3', 'language_pattern']].copy()
df_hf3.rename(columns={'fan_type_hf3': 'fan_type'}, inplace=True)
df_hf3.to_csv("labeled_comments_hylt_hf3category.csv", index=False, encoding="utf-8-sig")

print(f"\nğŸ’¾ SAVED HUGGINGFACE 3-CATEGORY RESULTS:")
print(f"   âœ… labeled_comments_hylt_hf3category.csv")

# ============================================
# å¯¹æ¯”åˆ†æå»ºè®®
# ============================================

print(f"\nğŸ¯ NEXT STEPS:")
print(f"   1. ğŸ“Š Compare HF 3-category vs Rule-based 3-category results")
print(f"   2. ğŸ”„ Choose the better performing approach")
print(f"   3. ğŸµ Proceed to Spotify audio features analysis")
print(f"   4. ğŸ“ˆ Build correlation analysis between audio features and fan reactions")

print(f"\nğŸ’¡ RECOMMENDATION:")
if specific_ratio > 60:
    print(f"   ğŸ‰ HuggingFace 3-category works well! Use this for final analysis.")
elif specific_ratio > 45:
    print(f"   âœ… Decent results. Compare with rule-based approach.")
else:
    print(f"   ğŸ¤” May need to stick with rule-based approach or hybrid method.")

print(f"\nğŸ“ˆ HUGGINGFACE 3-CATEGORY CLASSIFICATION COMPLETE!")
