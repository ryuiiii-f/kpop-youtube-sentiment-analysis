import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
import re

print("ðŸ§  UNSUPERVISED DISCOVERY OF REAL FAN PATTERNS")
print("="*60)

# è¯»å–æ•°æ®
df = pd.read_csv("labeled_comments_hylt_hf.csv")

# 1. æ¸…ç†å’Œé¢„å¤„ç†
def clean_comment(text):
    if pd.isna(text):
        return ""
    text = str(text).lower()
    # ä¿ç•™å­—æ¯ã€æ•°å­—ã€ç©ºæ ¼ï¼Œç§»é™¤ç‰¹æ®Šç¬¦å·
    text = re.sub(r'[^a-zA-Z0-9\sê°€-íž£ã²ã‚‰ãŒãªã‚«ã‚¿ã‚«ãƒŠä¸€-é¾¯]', ' ', text)
    # åŽ‹ç¼©å¤šä¸ªç©ºæ ¼
    text = re.sub(r'\s+', ' ', text)
    return text.strip()

# æ¸…ç†è¯„è®º
df['comment_clean'] = df['comment_text'].apply(clean_comment)

# è¿‡æ»¤å¤ªçŸ­çš„è¯„è®ºï¼ˆè¿™äº›é€šå¸¸å°±æ˜¯general praiseï¼‰
df_filtered = df[df['comment_clean'].str.len() > 10].copy()
print(f"ðŸ“Š Filtered comments: {len(df_filtered)} / {len(df)} (removed short comments)")

# 2. TF-IDFå‘é‡åŒ–
print("\nðŸ”§ Creating TF-IDF vectors...")
vectorizer = TfidfVectorizer(
    max_features=200,  # é™åˆ¶ç‰¹å¾æ•°
    ngram_range=(1, 2),  # åŒ…å«å•è¯å’ŒåŒè¯ç»„åˆ
    min_df=3,  # è¯æ±‡è‡³å°‘å‡ºçŽ°3æ¬¡
    max_df=0.8,  # æŽ’é™¤è¿‡äºŽå¸¸è§çš„è¯
    stop_words=None  # ä¸ä½¿ç”¨åœç”¨è¯ï¼ˆå› ä¸ºå¤šè¯­è¨€ï¼‰
)

tfidf_matrix = vectorizer.fit_transform(df_filtered['comment_clean'])
feature_names = vectorizer.get_feature_names_out()

print(f"âœ… TF-IDF matrix shape: {tfidf_matrix.shape}")

# å®šä¹‰èšç±»è§£é‡Šå‡½æ•°
def interpret_cluster(keywords, sample_comments):
    """åŸºäºŽå…³é”®è¯å’Œæ ·æœ¬è¯„è®ºè§£é‡Šèšç±»å«ä¹‰"""
    keywords_str = ' '.join(keywords).lower()
    
    # Visualç›¸å…³
    if any(word in keywords_str for word in ['look', 'visual', 'beautiful', 'pretty', 'hair', 'style', 'makeup']):
        return "Visual-Appearance Focused"
    
    # Music/Performanceç›¸å…³
    elif any(word in keywords_str for word in ['music', 'song', 'dance', 'performance', 'beat', 'vocals']):
        return "Content-Performance Focused"
    
    # æ­Œæ›²æ ‡é¢˜/æ­Œè¯ç›¸å…³
    elif any(word in keywords_str for word in ['how you like that', 'like that', 'how you', 'lyrics', 'line']):
        return "Song-Title/Lyrics Focused"
    
    # æƒ…æ„Ÿè¡¨è¾¾
    elif any(word in keywords_str for word in ['love', 'amazing', 'perfect', 'best', 'good', 'great']):
        return "Emotional-Praise Focused"
    
    # äº’åŠ¨/ç¤¾åŒºç›¸å…³
    elif any(word in keywords_str for word in ['blink', 'fan', 'stream', 'support', 'forever']):
        return "Community-Support Focused"
    
    # å…¶ä»–
    else:
        return "Mixed-General Content"

# 3. å°è¯•ä¸åŒçš„èšç±»æ•°é‡
print("\nðŸ” Testing different cluster numbers...")

inertias = []
K_range = range(2, 8)

for k in K_range:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    kmeans.fit(tfidf_matrix)
    inertias.append(kmeans.inertia_)

# ç»˜åˆ¶è‚˜éƒ¨æ³•åˆ™å›¾
plt.figure(figsize=(10, 6))
plt.plot(K_range, inertias, 'bo-')
plt.xlabel('Number of Clusters')
plt.ylabel('Inertia')
plt.title('Elbow Method for Optimal Cluster Number')
plt.grid(True, alpha=0.3)
plt.savefig('clustering_elbow_method.png', dpi=300, bbox_inches='tight')
plt.show()
print("âœ… Saved: clustering_elbow_method.png")

# 4. ä½¿ç”¨æœ€ä¼˜èšç±»æ•°ï¼ˆå‡è®¾æ˜¯3-4ï¼‰
optimal_k = 4  # å¯ä»¥æ ¹æ®è‚˜éƒ¨å›¾è°ƒæ•´
print(f"\nðŸŽ¯ Performing clustering with k={optimal_k}...")

kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
cluster_labels = kmeans.fit_predict(tfidf_matrix)

# å°†èšç±»ç»“æžœåŠ å…¥æ•°æ®æ¡†
df_filtered['cluster'] = cluster_labels

# 5. åˆ†æžæ¯ä¸ªèšç±»çš„ç‰¹å¾
print(f"\nðŸ” ANALYZING DISCOVERED CLUSTERS:")
print("-" * 50)

cluster_insights = {}
for i in range(optimal_k):
    cluster_mask = cluster_labels == i
    cluster_size = np.sum(cluster_mask)
    
    if cluster_size > 5:  # åªåˆ†æžæœ‰è¶³å¤Ÿæ ·æœ¬çš„èšç±»
        # èŽ·å–è¯¥èšç±»çš„ä»£è¡¨æ€§è¯æ±‡
        cluster_center = kmeans.cluster_centers_[i]
        top_indices = cluster_center.argsort()[-15:][::-1]
        top_words = [feature_names[idx] for idx in top_indices]
        
        # èŽ·å–è¯¥èšç±»çš„æ ·æœ¬è¯„è®º
        cluster_comments = df_filtered[df_filtered['cluster'] == i]['comment_text'].tolist()
        cluster_emotions = df_filtered[df_filtered['cluster'] == i]['emotion'].value_counts()
        
        print(f"\nðŸ”¸ CLUSTER {i+1} ({cluster_size} comments, {cluster_size/len(df_filtered)*100:.1f}%):")
        print(f"   Key words: {', '.join(top_words[:8])}")
        print(f"   Top emotions: {dict(cluster_emotions.head(3))}")
        print(f"   Sample comments:")
        for j, comment in enumerate(cluster_comments[:2]):
            print(f"     '{comment[:60]}...'")
        
        # å°è¯•è§£é‡Šè¿™ä¸ªèšç±»
        interpretation = interpret_cluster(top_words, cluster_comments[:5])
        print(f"   ðŸ’¡ Possible interpretation: {interpretation}")
        
        cluster_insights[f"cluster_{i+1}"] = {
            'size': cluster_size,
            'percentage': cluster_size/len(df_filtered)*100,
            'keywords': top_words[:8],
            'interpretation': interpretation,
            'top_emotions': cluster_emotions.head(3).to_dict()
        }

# 6. å¯è§†åŒ–èšç±»ç»“æžœ
print(f"\nðŸ“Š Creating cluster visualization...")

# PCAé™ç»´å¯è§†åŒ–
pca = PCA(n_components=2, random_state=42)
tfidf_2d = pca.fit_transform(tfidf_matrix.toarray())

plt.figure(figsize=(12, 8))
colors = ['red', 'blue', 'green', 'orange', 'purple', 'brown']

for i in range(optimal_k):
    cluster_points = tfidf_2d[cluster_labels == i]
    plt.scatter(cluster_points[:, 0], cluster_points[:, 1], 
               c=colors[i], label=f'Cluster {i+1}', alpha=0.6)

plt.title('K-pop Comment Clusters (PCA Visualization)', fontsize=16, fontweight='bold')
plt.xlabel(f'First Principal Component ({pca.explained_variance_ratio_[0]:.1%} variance)')
plt.ylabel(f'Second Principal Component ({pca.explained_variance_ratio_[1]:.1%} variance)')
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('comment_clusters_pca.png', dpi=300, bbox_inches='tight')
plt.show()
print("âœ… Saved: comment_clusters_pca.png")

# 7. åˆ›å»ºæ–°çš„åˆ†ç±»ç³»ç»Ÿ
print(f"\nðŸŽ¯ CREATING DATA-DRIVEN CLASSIFICATION SYSTEM:")
print("-" * 50)

# åŸºäºŽå‘çŽ°çš„èšç±»åˆ›å»ºæ–°çš„fan_type
def assign_data_driven_type(cluster_num, cluster_insights):
    """åŸºäºŽèšç±»åˆ†æžç»“æžœåˆ†é…ç±»åž‹"""
    if f"cluster_{cluster_num+1}" in cluster_insights:
        interpretation = cluster_insights[f"cluster_{cluster_num+1}"]['interpretation']
        
        if "Visual" in interpretation:
            return "visual-focused"
        elif "Content" in interpretation or "Performance" in interpretation:
            return "content-focused"
        elif "Song-Title" in interpretation or "Lyrics" in interpretation:
            return "song-reference-focused"  # æ–°å‘çŽ°çš„ç±»åž‹ï¼
        elif "Community" in interpretation:
            return "community-focused"  # æ–°ç±»åž‹ï¼
        else:
            return "general-praise"
    return "general-praise"

# ä¸ºè¿‡æ»¤åŽçš„æ•°æ®åˆ†é…æ–°ç±»åž‹
df_filtered['fan_type_discovered'] = df_filtered['cluster'].apply(
    lambda x: assign_data_driven_type(x, cluster_insights)
)

# ç»Ÿè®¡æ–°çš„åˆ†ç±»ç»“æžœ
discovered_counts = df_filtered['fan_type_discovered'].value_counts()
print(f"\nðŸ“Š DATA-DRIVEN CLASSIFICATION RESULTS:")
for category, count in discovered_counts.items():
    percentage = count/len(df_filtered)*100
    print(f"   {category}: {count} ({percentage:.1f}%)")

# ä¿å­˜å‘çŽ°çš„åˆ†ç±»ç»“æžœ
df_filtered[['comment_text', 'emotion', 'fan_type_discovered', 'cluster']].to_csv(
    "labeled_comments_discovered_types.csv", index=False, encoding="utf-8-sig"
)

print(f"\nðŸ’¾ SAVED DATA-DRIVEN RESULTS:")
print(f"   âœ… labeled_comments_discovered_types.csv")
print(f"   âœ… clustering_elbow_method.png")
print(f"   âœ… comment_clusters_pca.png")

print(f"\nðŸ¤” ANALYSIS CONCLUSION:")
if len(discovered_counts) > 1 and discovered_counts.iloc[0] / len(df_filtered) < 0.8:
    print(f"   âœ… Found meaningful patterns in the data!")
    print(f"   ðŸŽ¯ Use these discovered types for further analysis")
else:
    print(f"   ðŸ“ Comments are naturally homogeneous (mostly general praise)")
    print(f"   ðŸ’¡ This is a valid finding - most K-pop fans express general positive emotions")
    print(f"   ðŸš€ Recommend focusing on emotion analysis instead of fan types")

print(f"\nðŸŽµ READY FOR SPOTIFY AUDIO FEATURES ANALYSIS!")
